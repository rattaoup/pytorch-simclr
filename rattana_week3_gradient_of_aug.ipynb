{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlars import LARS\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs import get_datasets\n",
    "from critic import LinearCritic\n",
    "from evaluate import save_checkpoint,save_checkpoint2, encode_train_set, train_clf, test\n",
    "from models import *\n",
    "from scheduler import CosineAnnealingWithLinearRampLR\n",
    "from augmentation import ManualNormalise, DifferentiableColourDistortionByTorch3\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numbers\n",
    "import random\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img.to('cpu')\n",
    "    #img = img / 2 + 0.5     \n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "### config ####\n",
    "num_workers = 16\n",
    "batch_size = 512\n",
    "img_size = 32\n",
    "temperature = 0.5\n",
    "dataset = 'cifar10'\n",
    "CACHED_MEAN_STD = {\n",
    "        'cifar10': ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        'cifar100': ((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023)),\n",
    "        'stl10': ((0.4409, 0.4279, 0.3868), (0.2309, 0.2262, 0.2237)),\n",
    "        'imagenet': ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    }\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 0.25\n",
    "arch = 'resnet18'\n",
    "momentum = 0.9\n",
    "cosine_anneal = True\n",
    "num_epochs = 1\n",
    "test_freq = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "lr = base_lr * (batch_size / 256)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "clf = None\n",
    "\n",
    "print('==> Preparing data..')\n",
    "trainset, testset, clftrainset, num_classes, stem = get_datasets(dataset)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                                          num_workers=num_workers, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=num_workers,\n",
    "                                         pin_memory=True)\n",
    "clftrainloader = torch.utils.data.DataLoader(clftrainset, batch_size=1000, shuffle=False, num_workers=num_workers,\n",
    "                                             pin_memory=True)\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "##############################################################\n",
    "# Encoder\n",
    "##############################################################\n",
    "if arch == 'resnet18':\n",
    "    net = ResNet18(stem=stem)\n",
    "elif arch == 'resnet34':\n",
    "    net = ResNet34(stem=stem)\n",
    "elif arch == 'resnet50':\n",
    "    net = ResNet50(stem=stem)\n",
    "else:\n",
    "    raise ValueError(\"Bad architecture specification\")\n",
    "net = net.to(device)\n",
    "\n",
    "##############################################################\n",
    "# Critic\n",
    "##############################################################\n",
    "critic = LinearCritic(net.representation_dim, temperature=temperature).to(device)\n",
    "#differentiable augmentation\n",
    "s = 1.0\n",
    "aug_by_torch_batch = DifferentiableColourDistortionByTorch3(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "\n",
    "if device == 'cuda':\n",
    "    repr_dim = net.representation_dim\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    net.representation_dim = repr_dim\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "base_optimizer = optim.SGD(list(net.parameters()) + list(critic.parameters()), lr=lr, weight_decay=1e-6,\n",
    "                           momentum=momentum)\n",
    "if cosine_anneal == True:\n",
    "    scheduler = CosineAnnealingWithLinearRampLR(base_optimizer, num_epochs)\n",
    "    encoder_optimizer = LARS(base_optimizer, trust_coef=1e-3)\n",
    "\n",
    "##############################################################\n",
    "# Training\n",
    "##############################################################\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    critic.train()\n",
    "    train_loss = 0\n",
    "    t = tqdm(enumerate(trainloader), desc='Loss: **** ', total=len(trainloader), bar_format='{desc}{bar}{r_bar}')\n",
    "    for batch_idx, (inputs, _, _) in t:\n",
    "        x1, x2 = inputs\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "        \n",
    "        x1, x2 = aug_by_torch_batch(x1), aug_by_torch_batch(x2)\n",
    "        x1, x2 = ManualNormalise(x1, dataset), ManualNormalise(x2, dataset) \n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        representation1, representation2 = net(x1), net(x2)\n",
    "        raw_scores, pseudotargets = critic(representation1, representation2)\n",
    "        loss = criterion(raw_scores, pseudotargets)\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        t.set_description('Loss: %.3f ' % (train_loss / (batch_idx + 1)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient penalty 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentiableColourDistortionByTorch_manual(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    need to input the parameter of color augmentation \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n",
    "        super().__init__()\n",
    "        self.brightness = brightness\n",
    "        self.contrast = contrast\n",
    "        self.saturation = saturation\n",
    "        self.hue = hue\n",
    "\n",
    "    \n",
    "    #### batch color augmentation forward #####\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x: Input tensor batchsize x 32 x 32\n",
    "        \n",
    "        Returns:\n",
    "            x_aug : color jittered image\n",
    "            \n",
    "        apply color jitter with prob 0.8\n",
    "        apply random grayscale with prob 0.2\n",
    "        \n",
    "        '''\n",
    "        batch_size = x.size()[0]\n",
    "        \n",
    "        p_jitter = torch.ones(batch_size) * 0.8\n",
    "        jitter = torch.bernoulli(p_jitter)\n",
    "        jitter = jitter.reshape(batch_size,1,1,1)\n",
    "\n",
    "        p_gray = torch.ones(batch_size)* 0.2\n",
    "        gray = torch.bernoulli(p_gray)\n",
    "        gray = gray.reshape(batch_size,1,1,1)\n",
    "\n",
    "        jitter = jitter.to(x.device)\n",
    "        gray = gray.to(x.device)\n",
    "        \n",
    "        #random color jitter\n",
    "        x_jitter = self.batch_colourjitter(x)\n",
    "        x = x_jitter * jitter + x *(1-jitter)\n",
    "        \n",
    "        #random gray scale\n",
    "        x_gray = self.batch_rgb_to_grayscale(x).unsqueeze(1)\n",
    "        x = x_gray * gray + x* (1-gray)\n",
    "       \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def batch_colourjitter(self, img: Tensor) -> Tensor:\n",
    "        \n",
    "        fn_idx = torch.randperm(4)\n",
    "        for fn_id in fn_idx:\n",
    "            if fn_id == 0 and self.brightness is not None:\n",
    "                brightness_list = self.brightness\n",
    "                img = self.batch_adjust_brightness(img, brightness_list)\n",
    "\n",
    "            if fn_id == 1 and self.contrast is not None:\n",
    "                contrast_list = self.contrast\n",
    "                img = self.batch_adjust_contrast(img, contrast_list)\n",
    "\n",
    "            if fn_id == 2 and self.saturation is not None:\n",
    "                saturation_list = self.saturation\n",
    "                img = self.batch_adjust_saturation(img, saturation_list)\n",
    "\n",
    "            if fn_id == 3 and self.hue is not None:\n",
    "                hue_list = self.hue\n",
    "                img = self.batch_adjust_hue(img, hue_list)\n",
    "\n",
    "        return img\n",
    "        \n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        format_string += 'brightness={0}'.format(self.brightness)\n",
    "        format_string += ', contrast={0}'.format(self.contrast)\n",
    "        format_string += ', saturation={0}'.format(self.saturation)\n",
    "        format_string += ', hue={0})'.format(self.hue)\n",
    "        return format_string\n",
    "                \n",
    "    ##### function from pytorch source code #####\n",
    "    def _is_tensor_a_torch_image(self, x: Tensor) -> bool:\n",
    "        return x.ndim >= 2\n",
    "    \n",
    "    def _blend(self, img1: Tensor, img2: Tensor, ratio: float) -> Tensor:\n",
    "        bound = 1 if img1.dtype in [torch.half, torch.float32, torch.float64] else 255\n",
    "        return (ratio * img1 + (1 - ratio) * img2).clamp(0, bound).to(img1.dtype)\n",
    "    def batch_adjust_brightness(self,img: Tensor, brightness_list: list) -> Tensor:\n",
    "        '''\n",
    "        Batch x C x H x  W -> Batch x C x H x W\n",
    "        '''\n",
    "        B = img.size()[0]\n",
    "        brightness_factor = brightness_list.reshape(B,1,1,1).to(img.device)\n",
    "        return self._blend(img, torch.zeros_like(img), brightness_factor)\n",
    "    \n",
    "    def batch_rgb_to_grayscale(self,img: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Batch x C x H x  W -> Batch x C x H x W\n",
    "        '''\n",
    "        if img.shape[1] != 3:\n",
    "            raise TypeError('Input Image does not contain 3 Channels')\n",
    "\n",
    "        img_tp = img.transpose(0,1)\n",
    "        img_gray = (0.2989 * img_tp[0] + 0.5870 * img_tp[1] + 0.1140 * img_tp[2])\n",
    "        return img_gray\n",
    "    \n",
    "    def batch_adjust_saturation(self,img: Tensor, saturation_list: list) -> Tensor:\n",
    "        '''\n",
    "        Batch x C x H x  W -> Batch x C x H x W\n",
    "        '''\n",
    "\n",
    "        B = img.size()[0]\n",
    "        saturation_factor = saturation_list.reshape(B,1,1,1).to(img.device)\n",
    "\n",
    "        return self._blend(img, self.batch_rgb_to_grayscale(img).unsqueeze(1), saturation_factor)\n",
    "    \n",
    "    def batch_adjust_contrast(self,img: Tensor, contrast_list: float) -> Tensor:\n",
    "        '''\n",
    "        Batch x C x H x  W -> Batch x C x H x W\n",
    "        '''\n",
    "        B = img.size()[0]\n",
    "        contrast_list = contrast_list.reshape(B,1,1,1).to(img.device)\n",
    "\n",
    "        #mean for each pic (over HxW points)\n",
    "        img_gray = self.batch_rgb_to_grayscale(img)\n",
    "        mean = torch.mean(img_gray.reshape(img_gray.shape[0],-1), dim = 1)\n",
    "\n",
    "\n",
    "        return self._blend(img, mean.reshape([mean.size()[0],1,1,1]),  contrast_list)\n",
    "    \n",
    "    def batch_adjust_hue(self, img: Tensor, hue_list: list) -> Tensor:\n",
    "        '''\n",
    "        Batch x C x H x  W -> Batch x C x H x W\n",
    "        '''\n",
    "\n",
    "        B = img.size()[0]\n",
    "\n",
    "        # generate tensor \n",
    "        one_tensor = torch.ones(B)\n",
    "        zero_tensor = torch.zeros(B)\n",
    "        cos_tensor = torch.cos(hue_list)\n",
    "        sin_tensor = torch.sin(hue_list)\n",
    "\n",
    "        #stack\n",
    "        T_hue = torch.stack([one_tensor, zero_tensor, zero_tensor,\n",
    "                     zero_tensor, cos_tensor, -sin_tensor,\n",
    "                     zero_tensor, sin_tensor, cos_tensor]).transpose(0,1).reshape(B,3,3)\n",
    "\n",
    "        T_yiq = torch.tensor([[0.299, 0.587, 0.114], [0.596, -0.274, -0.321], [0.211, -0.523, 0.311]])\n",
    "        T_rgb = torch.tensor([[1, 0.956, 0.621], [1, -0.272, -0.647], [1, -1.107, 1.705]])\n",
    "        T_final = torch.matmul(torch.matmul(T_rgb, T_hue), T_yiq)\n",
    "        T_final = T_final.to(img.device)\n",
    "\n",
    "        #return T_rgb x T_hue x T_yiq x img\n",
    "\n",
    "        return torch.matmul(T_final.unsqueeze(1).unsqueeze(1), img.transpose(1,-1).unsqueeze(-1)).squeeze(-1).transpose(1,-1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lambda(B, brightness_bound, contrast_bound, saturation_bound, hue_bound):\n",
    "    brightness_list = (torch.torch.rand(B)*(brightness_bound[1] - brightness_bound[0]) \n",
    "                   + brightness_bound[0]).requires_grad_(True)\n",
    "    saturation_list = (torch.torch.rand(B)*(saturation_bound[1] - saturation_bound[0]) \n",
    "                       + saturation_bound[0]).requires_grad_(True)\n",
    "    contrast_list   = (torch.torch.rand(B)*(contrast_bound[1] - contrast_bound[0]) \n",
    "                       + contrast_bound[0]).requires_grad_(True)\n",
    "    hue_list        = ((torch.torch.rand(B)*(hue_bound[1]-hue_bound[0]) \n",
    "                       + hue_bound[0])* 3.1415* 2).requires_grad_(True)\n",
    "    return brightness_list, saturation_list, contrast_list, hue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: **** ██████████| 98/98 [03:24<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "brightness_bound = [0.2, 1.8]\n",
    "contrast_bound = [0.2, 1.8]\n",
    "saturation_bound = [0.2, 1.8]\n",
    "hue_bound = [-0.2, 0.2]\n",
    "    \n",
    "epoch = 0\n",
    "print('\\nEpoch: %d' % epoch)\n",
    "net.train()\n",
    "critic.train()\n",
    "train_loss = 0\n",
    "t = tqdm(enumerate(trainloader), desc='Loss: **** ', total=len(trainloader), bar_format='{desc}{bar}{r_bar}')\n",
    "for batch_idx, (inputs, _, _) in t:\n",
    "    x1, x2 = inputs\n",
    "    x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "    ##### colour augmentation #####\n",
    "    B = x1.size()[0]\n",
    "    brightness_list1, saturation_list1, contrast_list1, hue_list1 = gen_lambda(B, brightness_bound, \n",
    "                                                                               contrast_bound,\n",
    "                                                                               saturation_bound,\n",
    "                                                                               hue_bound)\n",
    "    aug_manual1 = DifferentiableColourDistortionByTorch_manual(brightness = brightness_list1,\n",
    "                                                              contrast = contrast_list1,\n",
    "                                                              saturation = saturation_list1,\n",
    "                                                              hue = hue_list1)\n",
    "\n",
    "    brightness_list2, saturation_list2, contrast_list2, hue_list2 = gen_lambda(B, brightness_bound, \n",
    "                                                                               contrast_bound,\n",
    "                                                                               saturation_bound,\n",
    "                                                                               hue_bound)\n",
    "\n",
    "    aug_manual2 = DifferentiableColourDistortionByTorch_manual(brightness = brightness_list2,\n",
    "                                                              contrast = contrast_list2,\n",
    "                                                              saturation = saturation_list2,\n",
    "                                                              hue = hue_list2)\n",
    "  \n",
    "    x1, x2 = aug_manual1(x1), aug_manual2(x2)\n",
    "    \n",
    "    #####\n",
    "    x1, x2 = ManualNormalise(x1, dataset), ManualNormalise(x2, dataset)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    representation1, representation2 = net(x1), net(x2)\n",
    "    raw_scores, pseudotargets = critic(representation1, representation2)\n",
    "    loss = criterion(raw_scores, pseudotargets)\n",
    "\n",
    "    ##### gradient penalty #####\n",
    "    gradient_lambda = []\n",
    "    lambda_list = [brightness_list1, saturation_list1, contrast_list1, hue_list1, \n",
    "                   brightness_list2, saturation_list2, contrast_list2, hue_list2 ]\n",
    "\n",
    "    for aug_variable in lambda_list:\n",
    "        gradients_augvar =  autograd.grad(outputs = loss,\n",
    "                             inputs = aug_variable,\n",
    "                             retain_graph = True,\n",
    "                             grad_outputs = torch.ones_like(aug_variable).to(device))[0]\n",
    "        gradient_lambda.append(gradients_augvar)\n",
    "\n",
    "    gradient_lambda = torch.stack(gradient_lambda, dim = 0)\n",
    "\n",
    "    # currently gradient_lamba.sum([0]).sqrt() has nan element? so I use norm instead\n",
    "    gradient_penalty = gradient_lambda.sum([0]).norm(2)\n",
    "\n",
    "    loss_gp = loss + 0.001*gradient_penalty\n",
    "    loss_gp.backward()\n",
    "    encoder_optimizer.step()\n",
    "    train_loss += loss_gp.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
